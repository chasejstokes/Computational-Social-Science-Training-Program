---
title: "Regression Discontinuity"
output:
  pdf_document: default
  html_document: default
---

# Regression Discontinuity

```{r}
# Install packages 
if (!require("pacman")) install.packages("pacman")

pacman::p_load(# Tidyverse packages including dplyr and ggplot2 
               tidyverse,
               rdd,
               ggthemes,
               tidymodels,
               here)

set.seed(1)
```

## Definition

In social sciences, a regression discontinuity design is a quasi-experimental pretest-posttest design that elicits the causal effects of interventions by assigning a cutoff or threshold above or below which an intervention is assigned. By comparing observations lying closely on either side of the threshold, it is possible to estimate the average treatment effect in environments in which randomization is unfeasible. 

## Treatment Using a Running Variable

In an ideal experiment, we would be able to randomly assign our units to treatment and control. However, as we've seen, this is not always possible in social science contexts. Let's consider a classic question from political science: do incumbent politicians enjoy an incumbency advantage? In other words, do incumbents garner a higher vote share than they would if they were running for the first time?

To explore this question, we are going to use data taken from [Lee (2008)](https://www.nber.org/papers/w8441). We have a few variables to define:

- `difshare`: Normalized proportion of vote share the party received in the last election
- `yearel`: Year of current election
- `myoutcomenext`: 0/1 binary for whether the candidate won re-election
- `win_relection`: "win"/"lose" whether the candidate won re-election
- `incumbent`: 0/1 for whether the candidate is an incumbent

```{r}
# update with here()
elections <- read_csv('../../data/indiv_final.csv')

elections <- elections %>%
  mutate(win_reelection = ifelse(myoutcomenext == 1,
                                 'win',
                                 'lose')) %>%
  mutate(incumbent = ifelse(difshare > 0, 
                            1, 
                            0))
```

Suppose we are interested in the effect of incumbency on the probability of winning re-election. We might look at the distribution of vote shares by incumbency. Let's look at this boxplot:

```{r}
elections %>%
  mutate(incumbent = as.factor(incumbent)) %>%
  ggplot() +
  geom_boxplot(aes(x = incumbent, 
                   y = difshare, 
                   group = incumbent, 
                   fill = incumbent)) +
  ggtitle('Boxplot of Vote Share Among \n Incumbents') +
  theme_fivethirtyeight()
``` 

Looks like incumbents enjoy a pretty significant advantage! Let's investigate this further by this using a linear probability model:

```{r}
election_lm <- lm(myoutcomenext ~ incumbent, 
                   data = elections)
summary(election_lm)
```

Incumbency is a statistically significant covariate! 

What might be the problem with using .77 as the coefficient in this case? Let's take at the distribution of previous elections voteshares between winners and losers. 


```{r}
elections %>% 
  mutate(incumbent = as.factor(incumbent)) %>%
  mutate(decile = as.factor(ntile(difshare, 10))) %>%
  ggplot() +
  geom_bar(aes(y = decile,
               fill = win_reelection),
           position = 'dodge') +
  ggtitle('Barplot of Re-Election Winners by \n Previous Election Vote Share Decile') +
  theme_fivethirtyeight() +
  coord_flip()
```

**Question**: Groups 1 - 4 look ok - by definition someone cannot win reelection if they lost the last election. But what about the difference in distributions between deciles like 5 and 6, versus the distributions in deciles 7-10? Why would these different distributions pose a problem for trusting our previous point estimate?

**Solution**: Our main worry is that people who won huge proportions of the vote in the last election are systematically different from those who barely won in the last election. For instance, it should not be surprising when a Democratic incumbent carries CA-13 (Berkeley's congressional district) not because they enjoy an incumbency advantage but because the district is heavily Democratic for other reasons. 

## Running Variable

We might assume that the selection into treatment/control conditions is driven entirely by observable characteristics (selection on the observables). If this was the case, then we could add these characteristics as controls to our regression, and we would be ok. In practice, this is rarely a realistic assumption though, and we most likely will worry about selection on unobservable characteristics - essentially confounders that we do not see but affect both treatment and the outcome. 

The basic intuition behind regression discontinuity designs is that we use a **running variable** that determines whether a unit was assigned to either treatment or control. Let's take a look:

```{r}
elections %>%
  ggplot() + 
  geom_density(aes(x = difshare)) +
  ggtitle('Density of Normalized Voteshare') + 
  geom_vline(xintercept = 0) +
  theme_fivethirtyeight() 
```

"0" here is the cutpoint we use to assign someone to either incumbent or non-incumbent treatment conditions. The basic logic behind the RD is that those individuals on either side of the cutpoints will be very similar to each other in terms of baseline covariates (on both observed and unobserved characteristics).

## McCrary Density Test

Before we estimate model for individuals on either side of the cutpoint though, we might be concerned about their manipulation into treatment and control. For example, if the running variable was a passing test score to move onto to the next grade, you might imagine that a teacher bumps up a student from a 59 to a 60. Similarly, if the cutoff to be recruited into an honors program is a 90, you might worry that a student with an 89 who knows that they could appeal to be admitted anyway differs from the student who does not think such a thing is negotiable.

[McCrary](https://www.nber.org/system/files/working_papers/t0334/t0334.pdf) proposes a test for this kind of problem. Specifically, he motivates the test by giving an example of patients who are assigned to either waiting room A or B, but only waiting room A receives the experimental treatment. Patients learn about this fact, so as those who are assigned to waiting room B are are walking there, they instead decide to go to waiting room A. Given enough patients doing this, we should expect waiting room A to become crowded and waiting room B to be relatively empty. Let's see what that looks like graphically in our dataset:

```{r}
elections %>%
  filter(difshare > -.05 & difshare < .05) %>%
  ggplot() +
  geom_histogram(aes(x = difshare, 
                   group = as.factor(incumbent),
                   fill = as.factor(incumbent)))
```
It looks like there isn't evidence of sorting at the cutpoint - in fact the distributions look identical. McCrary points out that these types of histograms can be biased at the cutpoint. He instead advocates for using local linear regressions to smooth the histograms at the cutpoint. Luckily, this procedure is implemented for us in the [rdd package](https://cran.r-project.org/web/packages/rdd/rdd.pdf):

```{r}
DCdensity(elections$difshare, 
          cutpoint = 0,
          verbose = TRUE,
          ext.out = TRUE,
          htest = TRUE)
```

The hypothesis test is looking to see whether the density of the points is statistically different at the cutpoint. Here we do not see evidence of this (it would be hard to manipulate winning an election!).

## Sharp Discontinuity

We can go ahead and estimate our model now! Once again the `rdd` package provides a nice function to let us do this:

```{r}
sharp_rdd_model <- RDestimate(# formula. outcome regressed on running variable x 
           # add a | c1 + c2... to add additional covariates
          # y ~ x | c1 + c2...cn
           myoutcomenext ~ difshare, 
           # data
           data = elections,
           # specify cutpoint
           cutpoint = 0,
           # specify bandwidth from Lee paper
           bw = .25,
           # return a model object
           model = TRUE)

sharp_rdd_model
```

**Question**: How does our LATE compare to the .77 estimate we saw before?

**Solution**: Much lower, a difference of about 20% in predicted probability of being re-elected.


## Fuzzy Discontinuity

We can also easily implement a fuzzy RD design. As we discussed in lecture, a fuzzy RD does not use one cutoff to assign to treatment and control, but rather uses the running variable as an instrument. To do a fuzzy RD, you simply need to add a `z` to your formula to indicate the treatment variable. 

```{r}
fuzzy_rdd_model <- RDestimate(# formula. outcome regressed on running variable x 
          # To change this to a fuzzy rdd, add a +z to the formula to indicate the treatment variable
           # add a | c1 + c2... to add additional covariates
          # formula = y ~ x + z + c1 + c2
           formula = myoutcomenext ~ difshare + incumbent, 
           # data
           data = elections,
           # specify cutpoint
           cutpoint = 0,
           # specify bandwidth from Lee paper
           bw = .25,
           # return a model object
           model = TRUE)

fuzzy_rdd_model
```

**Question**: Our LATE for both the Sharp and Fuzzy models was the same here. Does that make sense?

**Solution**: Yes! Because we defined our treatment indicator in sharp terms relative to our running variable, the sharp and fuzzy designs should be identical in this case.

## Bandwidth Selection

One of the main drawbacks of the regression discontinuity design is determining the optimal choice of bandwidth around the cutpoint. The intuition is that we want to pick a bandwidth such that the units on either side are very similar on both observed and unobserved characteristics - but if we knew how to do that then we could just use all of the data and matching! One way to select the bandwidth might be theory-driven in that the analyst picks the bandwidth that they think should yield unbiased estimates. 

The `rdd` package implements the [Imbens-Kalyanaraman](https://www.nber.org/system/files/working_papers/w14726/w14726.pdf) method to approach this problem. Imbens and Kalyanaraman advocate for optimizing the mean squared error using an algorithm that basically:

- Chooses an initial bandwidth and calculates the conditional expectation function and variance of y at the cutpoint
- Chooses a second initial bandwidth and do the same thing but calculate a second derivative of the CEF
- Add a regularization penalty

By iterating on these steps, we can eventually find the optimal bandwidth. Luckily, this is also implemented for us and we can just leave the `bw` argument blank by default to do this calculation:

```{r}
rdd_model <- RDestimate(# formula. outcome regressed on running variable x .
           # add a | c1 + c2... to add additional covariates
           myoutcomenext ~ difshare, 
           # data
           data = elections,
           # specify cutpoint
           cutpoint = 0)
```

How did the Imbens-Kalyanaraman bandwidth estimate compare to our choice of .25?

### Challenge

Another option is to use cross-validation. The basic procedure here is:

- Choose several values of bandwidths to search through then for each bandwidth value:
    - Split the data into v-folds
    - Estimate a RDD model using that bandwidth and calculate the MSE in each fold
    - Average the MSE across folds
- Select the bandwidth with the lowest MSE

See if you can implement these steps for cross-validation on your own! In the solutions, we make use of a few of the more advanced/latest tools in R like `predict()`, [vfold](https://rsample.tidymodels.org/reference/vfold_cv.html) from [tidymodels](https://www.tidymodels.org/), and [purrr](https://purrr.tidyverse.org/), a functional programming library that is part of the tidyverse. You may use these tools, or whatever else you like to attempt this challenge! Find an optimal bandwidth using this procedure, and report your average treatment effect. 

Also note that the `RDEstimate()` function returns an object with class "RD". See if you can extract the model object from it for calculating the MSE.

## Solution to CV Bandwidth

1. The first step here is to create a function that we will use to estimate a regression discontinuity and calculate the Mean Squared Error.

```{r}
calculate_rdd_and_bandwidth <- function(df_split, bw) {
  rdd_model <- RDestimate(# formula. outcome regressed on running variable x 
           # add a | c1 + c2... to add additional covariates
           myoutcomenext ~ difshare, 
           # data
           data = df_split,
           # specify cutpoint
           cutpoint = 0,
           # specify bandwidth from Lee paper
           bw = bw,
           # return a model object
           model = TRUE)
  
  # Use predict() to get predictions from the model, compare them to the actual values of myoutcomenext, return the mean
  mse_data <- data.frame(pred = predict(rdd_model$model[[1]]), 
                         actual = (df_split %>% filter(difshare >= -bw & difshare <= bw))$difshare)
  return(mean((mse_data$actual - mse_data$pred)^2))
}
```

2. Now we need to split our data. The `vfold()` function from `tidymodels` is similar to `train_test_split()` or `Kfold()` in Python's sklearn

3. Then we use the `map()` function from `purrr` to grab the data associated with each split using the "assessment" feature. We can then use `compose()` to prepare our rdd's for each split. For now we'll set a constant bw to test our function.

4. Then we use `map2()` to map our tidy functions and our custom rdd function to each split. **Note**: This operation returns *v* tibbles instead of a numeric vector, so we bind rows and then grab the mean

```{r, warning = FALSE}
# V-fold split
elections_vfold <- vfold_cv(elections, v = 10, repeats = 1)

elections_vfold <- elections_vfold %>%
  mutate(df_split = map(splits, assessment))

tidy_rdd_model <- purrr::compose( # compose multiple functions
  broom::tidy, # convert lm objects into tidy tibbles
  calculate_rdd_and_bandwidth
)

bw = .25

tidied_models <- elections_vfold %>%
  mutate(rdd = map2(df_split, bw, tidy_rdd_model))

mean(bind_rows(tidied_models$rdd)$x)
```

5. Now that we know this works for one value of bw, let's loop through 10 values of bw by incrementing from .01 to 1 in a for loop and performing the same operations. We'll return our average mean squared errors to a list and see which one was the lowest.

```{r, warning = FALSE}
bw_seq <- seq(.01, 1, .05)

mses <- c()
counter = 1

for (bw in bw_seq){
  elections_vfold <- vfold_cv(elections, v = 10, repeats = 1)

  elections_vfold <- elections_vfold %>%
    mutate(df_split = map(splits, assessment))
  
  tidy_rdd_model <- purrr::compose( # compose multiple functions
    broom::tidy, # convert lm objects into tidy tibbles
    calculate_rdd_and_bandwidth
  )
  
  tidied_models <- elections_vfold %>%
    mutate(rdd = map2(df_split, bw, tidy_rdd_model))
  
  mses[counter] <- mean(bind_rows(tidied_models$rdd)$x)
  counter = counter + 1
}
```

Looks like .1913 was our lowest in this case, corresponding to our 11th bw, .51. Let's check our ATT for this run:

```{r}
RDestimate(# formula. outcome regressed on running variable x 
           # add a | c1 + c2... to add additional covariates
           myoutcomenext ~ difshare, 
           # data
           data = elections,
           # specify cutpoint
           cutpoint = 0,
           # specify bandwidth from Lee paper
           bw = .51,
           # return a model object
           model = TRUE)
```